{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3385d377",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "This is a self contained guide on how to write a simple app and start launching\n",
    "distributed jobs on local and remote clusters.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First thing we need to do is to install the TorchX python package which includes\n",
    "the CLI and the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5804a",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "```sh\n",
    "# install torchx with all dependencies\n",
    "$ pip install torchx[dev]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b99379",
   "metadata": {},
   "source": [
    "See the [README](https://github.com/pytorch/torchx) for more\n",
    "information on installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319c7862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:04.976670Z",
     "iopub.status.busy": "2022-03-11T23:52:04.976413Z",
     "iopub.status.idle": "2022-03-11T23:52:06.328571Z",
     "shell.execute_reply": "2022-03-11T23:52:06.327515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: torchx [-h] [--log_level LOG_LEVEL] [--version]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              {describe,log,run,builtins,runopts,status,configure} ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchx CLI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -h, --help            show this help message and exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --log_level LOG_LEVEL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Python logging log level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --version             show program's version number and exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-commands:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Use the following commands to run operations, e.g.: torchx run ${JOB_NAME}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  {describe,log,run,builtins,runopts,status,configure}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484218b",
   "metadata": {},
   "source": [
    "## Hello World\n",
    "\n",
    "Lets start off with writing a simple \"Hello World\" python app. This is just a\n",
    "normal python program and can contain anything you'd like.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<div class=\"admonition-title\">Note</div>\n",
    "This example uses Jupyter Notebook `%%writefile` to create local files for\n",
    "example purposes. Under normal usage you would have these as standalone files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b978db80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:06.333822Z",
     "iopub.status.busy": "2022-03-11T23:52:06.333304Z",
     "iopub.status.idle": "2022-03-11T23:52:06.339214Z",
     "shell.execute_reply": "2022-03-11T23:52:06.338564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app.py\n",
    "\n",
    "import sys\n",
    "\n",
    "print(f\"Hello, {sys.argv[1]}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f429e",
   "metadata": {},
   "source": [
    "## Launching\n",
    "\n",
    "We can execute our app via `torchx run`. The\n",
    "`local_cwd` scheduler executes the app relative to the current directory.\n",
    "\n",
    "For this we'll use the `utils.python` component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78fe2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:06.343216Z",
     "iopub.status.busy": "2022-03-11T23:52:06.342617Z",
     "iopub.status.idle": "2022-03-11T23:52:08.323242Z",
     "shell.execute_reply": "2022-03-11T23:52:08.322160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: torchx run <run args...> python  [--help] [-m M] [-c C]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        [--script SCRIPT] [--image IMAGE]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        [--name NAME] [--cpu CPU] [--gpu GPU]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        [--memMB MEMMB] [-h H]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        [--num_replicas NUM_REPLICAS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs ``python`` with the specified module, command or script on the specified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  args                  arguments passed to the program in sys.argv[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        (ignored with `--c`) (required)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --help                show this help message and exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -m M, --m M           run library module as a script (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -c C, --c C           program passed as string (may error if scheduler has a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        length limit on args) (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --script SCRIPT       .py script to run (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --image IMAGE         image to run on (default:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ghcr.io/pytorch/torchx:0.1.2dev0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --name NAME           name of the job (default: torchx_utils_python)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --cpu CPU             number of cpus per replica (default: 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --gpu GPU             number of gpus per replica (default: 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --memMB MEMMB         cpu memory in MB per replica (default: 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -h H, --h H           a registered named resource (if specified takes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precedence over cpu, gpu, memMB) (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --num_replicas NUM_REPLICAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        number of copies to run (each on its own container)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        (default: 1)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_cwd utils.python --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328871e",
   "metadata": {},
   "source": [
    "The component takes in the script name and any extra arguments will be passed to\n",
    "the script itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1a9161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:08.327604Z",
     "iopub.status.busy": "2022-03-11T23:52:08.327121Z",
     "iopub.status.idle": "2022-03-11T23:52:12.660782Z",
     "shell.execute_reply": "2022-03-11T23:52:12.659781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:10 INFO     Log files located in: /tmp/torchx_1pgq6p1v/torchx/torchx_utils_python-p33mhg50mbkmcd/python/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:11 INFO     Waiting for the app to finish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0 Hello, your name!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:12 INFO     Job finished: SUCCEEDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_cwd://torchx/torchx_utils_python-p33mhg50mbkmcd\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_cwd utils.python --script my_app.py \"your name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2908219",
   "metadata": {},
   "source": [
    "We can run the exact same app via the `local_docker` scheduler. This scheduler\n",
    "will package up the local workspace as a layer on top of the specified image.\n",
    "This provides a very similar environment to the container based remote\n",
    "schedulers.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<div class=\"admonition-title\">Note</div>\n",
    "This requires Docker installed and won't work in environments such as Google\n",
    "Colab. See the Docker install instructions:\n",
    "[https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1241bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:12.665136Z",
     "iopub.status.busy": "2022-03-11T23:52:12.664919Z",
     "iopub.status.idle": "2022-03-11T23:52:28.401731Z",
     "shell.execute_reply": "2022-03-11T23:52:28.400754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:14 INFO     Building workspace: file:///home/runner/work/torchx/torchx/docs/source for role[0]: python, image: ghcr.io/pytorch/torchx:0.1.2dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:25 INFO     Done building workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:25 INFO     New image: sha256:86433e309ca0e7c89357f9ec8c04bb9d4c114ae23e5475d7b2e06e1a773124ca built from workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:27 INFO     Waiting for the app to finish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0 Hello, your name!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:28 INFO     Job finished: SUCCEEDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_docker://torchx/torchx_utils_python-trlkxfsvhm0pqc\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_docker utils.python --script my_app.py \"your name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca58b53",
   "metadata": {},
   "source": [
    "TorchX defaults to using the\n",
    "[ghcr.io/pytorch/torchx](https://ghcr.io/pytorch/torchx) Docker container image\n",
    "which contains the PyTorch libraries, TorchX and related dependencies.\n",
    "\n",
    "## Distributed\n",
    "\n",
    "TorchX's `dist.ddp` component uses\n",
    "[TorchElastic](https://pytorch.org/docs/stable/distributed.elastic.html)\n",
    "to manage the workers. This means you can launch multi-worker and multi-host\n",
    "jobs out of the box on all of the schedulers we support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8692c9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:28.406280Z",
     "iopub.status.busy": "2022-03-11T23:52:28.405605Z",
     "iopub.status.idle": "2022-03-11T23:52:30.409929Z",
     "shell.execute_reply": "2022-03-11T23:52:30.408974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: torchx run <run args...> ddp  [--help] [--script SCRIPT] [-m M]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [--image IMAGE] [--name NAME] [-h H]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [--cpu CPU] [--gpu GPU] [--memMB MEMMB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [-j J] [--env ENV]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [--max_retries MAX_RETRIES]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [--rdzv_backend RDZV_BACKEND]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     [--rdzv_endpoint RDZV_ENDPOINT]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed data parallel style application (one role, multi-replica). ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  script_args           arguments to the main module (required)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --help                show this help message and exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --script SCRIPT       script or binary to run within the image (default:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -m M, --m M           the python module path to run (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --image IMAGE         image (e.g. docker) (default:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ghcr.io/pytorch/torchx:0.1.2dev0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --name NAME           job name override (uses the script name if not\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        specified) (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -h H, --h H           a registered named resource (if specified takes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precedence over cpu, gpu, memMB) (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --cpu CPU             number of cpus per replica (default: 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --gpu GPU             number of gpus per replica (default: 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --memMB MEMMB         cpu memory in MB per replica (default: 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -j J, --j J           {nnodes}x{nproc_per_node}, for gpu hosts,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        nproc_per_node must not exceed num gpus (default: 1x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --env ENV             environment varibles to be passed to the run (e.g.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ENV1=v1,ENV2=v2,ENV3=v3) (default: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --max_retries MAX_RETRIES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        the number of scheduler retries allowed (default: 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --rdzv_backend RDZV_BACKEND\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        rendezvous backend (only matters when nnodes > 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        (default: c10d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --rdzv_endpoint RDZV_ENDPOINT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        rendezvous server endpoint (only matters when nnodes >\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        1), defaults to rank0 host for schedulers that support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        it (default: None)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_docker dist.ddp --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b04227",
   "metadata": {},
   "source": [
    "Lets create a slightly more interesting app to leverage the TorchX distributed\n",
    "support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9fb490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:30.413884Z",
     "iopub.status.busy": "2022-03-11T23:52:30.413641Z",
     "iopub.status.idle": "2022-03-11T23:52:30.420919Z",
     "shell.execute_reply": "2022-03-11T23:52:30.420088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dist_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dist_app.py\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "print(f\"I am worker {dist.get_rank()} of {dist.get_world_size()}!\")\n",
    "\n",
    "a = torch.tensor([dist.get_rank()])\n",
    "dist.all_reduce(a)\n",
    "print(f\"all_reduce output = {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ecb14",
   "metadata": {},
   "source": [
    "Let launch a small job with 2 nodes and 2 worker processes per node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb7089c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:30.424093Z",
     "iopub.status.busy": "2022-03-11T23:52:30.423884Z",
     "iopub.status.idle": "2022-03-11T23:52:54.322725Z",
     "shell.execute_reply": "2022-03-11T23:52:54.321709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:32 INFO     Building workspace: file:///home/runner/work/torchx/torchx/docs/source for role[0]: dist_app, image: ghcr.io/pytorch/torchx:0.1.2dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:42 INFO     Done building workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:42 INFO     New image: sha256:a7e32fbf2cc12556eed2e2b573d085ee746246a396b863eea388406212753110 built from workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:44 INFO     Waiting for the app to finish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 WARNING:__main__:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 *****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 *****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 WARNING:__main__:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 *****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 *****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 [0]:I am worker 2 of 4!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 [1]:I am worker 3 of 4!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 [0]:all_reduce output = tensor([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/1 [1]:all_reduce output = tensor([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 [0]:I am worker 0 of 4!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 [1]:I am worker 1 of 4!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 [0]:all_reduce output = tensor([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_app/0 [1]:all_reduce output = tensor([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:54 INFO     Job finished: SUCCEEDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_docker://torchx/dist_app-pkplvrqpbq7qtc\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_docker dist.ddp -j 2x2 --script dist_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ff7e5",
   "metadata": {},
   "source": [
    "## Workspaces / Patching\n",
    "\n",
    "For each scheduler there's a concept of an `image`. For `local_cwd` and `slurm`\n",
    "it uses the current working directory. For container based schedulers such as\n",
    "`local_docker`, `kubernetes` and `aws_batch` it uses a docker container.\n",
    "\n",
    "To provide the same environment between local and remote jobs, TorchX CLI uses\n",
    "workspaces to automatically patch images for remote jobs on a per scheduler\n",
    "basis.\n",
    "\n",
    "When you launch a job via `torchx run` it'll overlay the current directory on\n",
    "top of the provided image so your code is available in the launched job.\n",
    "\n",
    "For `docker` based schedulers you'll need a local docker daemon to build and\n",
    "push the image to your remote docker repository.\n",
    "\n",
    "## `.torchxconfig`\n",
    "\n",
    "Arguments to schedulers can be specified either via a command line flag to\n",
    "`torchx run -s <scheduler> -c <args>` or on a per scheduler basis via a\n",
    "`.torchxconfig` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd5d354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:54.327576Z",
     "iopub.status.busy": "2022-03-11T23:52:54.327249Z",
     "iopub.status.idle": "2022-03-11T23:52:54.333139Z",
     "shell.execute_reply": "2022-03-11T23:52:54.332378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .torchxconfig\n"
     ]
    }
   ],
   "source": [
    "%%writefile .torchxconfig\n",
    "\n",
    "[kubernetes]\n",
    "queue=torchx\n",
    "image_repo=<your docker image repository>\n",
    "\n",
    "[slurm]\n",
    "partition=torchx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96da7d",
   "metadata": {},
   "source": [
    "## Remote Schedulers\n",
    "\n",
    "TorchX supports a large number of schedulers.\n",
    "Don't see yours?\n",
    "[Request it!](https://github.com/pytorch/torchx/issues/new?assignees=&labels=&template=feature-request.md)\n",
    "\n",
    "Remote schedulers operate the exact same way the local schedulers do. The same\n",
    "run command for local works out of the box on remote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90245ebc",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "```sh\n",
    "$ torchx run --scheduler slurm dist.ddp -j 2x2 --script dist_app.py\n",
    "$ torchx run --scheduler kubernetes dist.ddp -j 2x2 --script dist_app.py\n",
    "$ torchx run --scheduler aws_batch dist.ddp -j 2x2 --script dist_app.py\n",
    "$ torchx run --scheduler ray dist.ddp -j 2x2 --script dist_app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9db696",
   "metadata": {},
   "source": [
    "Depending on the scheduler there may be a few extra configuration parameters so\n",
    "TorchX knows where to run the job and upload built images. These can either be\n",
    "set via `-c` or in the `.torchxconfig` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92229e",
   "metadata": {},
   "source": [
    "All config options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c279dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:54.337601Z",
     "iopub.status.busy": "2022-03-11T23:52:54.337388Z",
     "iopub.status.idle": "2022-03-11T23:52:55.317422Z",
     "shell.execute_reply": "2022-03-11T23:52:55.316431Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_docker:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [copy_env=COPY_ENV]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        copy_env=COPY_ENV (typing.List[str], None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            list of glob patterns of environment variables to copy if not set in AppDef. Ex: FOO_*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_cwd:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [log_dir=LOG_DIR],[prepend_cwd=PREPEND_CWD],[auto_set_cuda_visible_devices=AUTO_SET_CUDA_VISIBLE_DEVICES]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        log_dir=LOG_DIR (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dir to write stdout/stderr log files of replicas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        prepend_cwd=PREPEND_CWD (bool, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            if set, prepends CWD to replica's PATH env var making any binaries in CWD take precedence over those in PATH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auto_set_cuda_visible_devices=AUTO_SET_CUDA_VISIBLE_DEVICES (bool, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sets the `CUDA_AVAILABLE_DEVICES` for roles that request GPU resources. Each role replica will be assigned one GPU. Does nothing if the device count is less than replicas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [partition=PARTITION],[time=TIME],[nomem=NOMEM],[comment=COMMENT],[constraint=CONSTRAINT],[mail-user=MAIL-USER],[mail-type=MAIL-TYPE]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        partition=PARTITION (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            The partition to run the job in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time=TIME (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            The maximum time the job is allowed to run for.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        nomem=NOMEM (bool, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            disables memory request to workaround https://github.com/aws/aws-parallelcluster/issues/2198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        comment=COMMENT (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Comment to set on the slurm job.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        constraint=CONSTRAINT (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Constraint to use for the slurm job.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mail-user=MAIL-USER (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User to mail on job end.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mail-type=MAIL-TYPE (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            What events to mail users on.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubernetes:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        queue=QUEUE,[namespace=NAMESPACE],[image_repo=IMAGE_REPO],[service_account=SERVICE_ACCOUNT]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    required arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        queue=QUEUE (str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Volcano queue to schedule job in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        namespace=NAMESPACE (str, default)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Kubernetes namespace to schedule job in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        image_repo=IMAGE_REPO (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            The image repository to use when pushing patched images, must have push access. Ex: example.com/your/container\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        service_account=SERVICE_ACCOUNT (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            The service account name to set on the pod specs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws_batch:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        queue=QUEUE,[image_repo=IMAGE_REPO]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    required arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        queue=QUEUE (str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            queue to schedule job in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        image_repo=IMAGE_REPO (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            The image repository to use when pushing patched images, must have push access. Ex: example.com/your/container\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    usage:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [cluster_config_file=CLUSTER_CONFIG_FILE],[cluster_name=CLUSTER_NAME],[dashboard_address=DASHBOARD_ADDRESS],[working_dir=WORKING_DIR],[requirements=REQUIREMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    optional arguments:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cluster_config_file=CLUSTER_CONFIG_FILE (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Use CLUSTER_CONFIG_FILE to access or create the Ray cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cluster_name=CLUSTER_NAME (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Override the configured cluster name.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dashboard_address=DASHBOARD_ADDRESS (str, 127.0.0.1:8265)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Use ray status to get the dashboard address you will submit jobs against\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        working_dir=WORKING_DIR (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Copy the the working directory containing the Python scripts to the cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        requirements=REQUIREMENTS (str, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Path to requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx runopts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242e505",
   "metadata": {},
   "source": [
    "## Custom Images\n",
    "\n",
    "### Docker-based Schedulers\n",
    "\n",
    "If you want more than the standard PyTorch libraries you can add custom\n",
    "Dockerfile or build your own docker container and use it as the base image for\n",
    "your TorchX jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fc8607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:55.321672Z",
     "iopub.status.busy": "2022-03-11T23:52:55.321071Z",
     "iopub.status.idle": "2022-03-11T23:52:55.325616Z",
     "shell.execute_reply": "2022-03-11T23:52:55.325158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing timm_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile timm_app.py\n",
    "\n",
    "import timm\n",
    "\n",
    "print(timm.models.resnet18())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f47b189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:55.329039Z",
     "iopub.status.busy": "2022-03-11T23:52:55.328695Z",
     "iopub.status.idle": "2022-03-11T23:52:55.333128Z",
     "shell.execute_reply": "2022-03-11T23:52:55.332424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile.torchx\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile.torchx\n",
    "\n",
    "FROM pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime\n",
    "\n",
    "RUN pip install timm\n",
    "\n",
    "COPY . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dfeed5",
   "metadata": {},
   "source": [
    "Once we have the Dockerfile created we can launch as normal and TorchX will\n",
    "automatically build the image with the newly provided Dockerfile instead of the\n",
    "default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffde3009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T23:52:55.336912Z",
     "iopub.status.busy": "2022-03-11T23:52:55.336610Z",
     "iopub.status.idle": "2022-03-11T23:53:13.212043Z",
     "shell.execute_reply": "2022-03-11T23:53:13.211021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:56 INFO     loaded configs from /home/runner/work/torchx/torchx/docs/source/.torchxconfig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:52:57 INFO     Building workspace: file:///home/runner/work/torchx/torchx/docs/source for role[0]: python, image: ghcr.io/pytorch/torchx:0.1.2dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:53:09 INFO     Done building workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:53:09 INFO     New image: sha256:5025aeac83d29cb3bf669eb0ee0b728659e9d742e7140f7d0f9275f92cd0a308 built from workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:53:10 INFO     Waiting for the app to finish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0 ResNet(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (layer1): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (0): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (1): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (layer2): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (0): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (downsample): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (1): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (layer3): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (0): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (downsample): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (1): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (layer4): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (0): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (downsample): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     (1): BasicBlock(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act1): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0       (act2): ReLU(inplace=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0     )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0   (fc): Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python/0 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2022-03-11 23:53:12 INFO     Job finished: SUCCEEDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_docker://torchx/torchx_utils_python-fbrzlrvxm95q9\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "torchx run --scheduler local_docker utils.python --script timm_app.py \"your name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aee5b5",
   "metadata": {},
   "source": [
    "### Slurm\n",
    "\n",
    "The `slurm` and `local_cwd` use the current environment so you can use `pip` and\n",
    "`conda` as normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8dafb",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Checkout other features of the [torchx CLI](cli.rst)\n",
    "2. Take a look at the [list of schedulers](schedulers.rst) supported by the runner\n",
    "3. Browse through the collection of [builtin components](components/overview.rst)\n",
    "4. See which [ML pipeline platforms](pipelines.rst) you can run components on\n",
    "5. See a [training app example](examples_apps/index.rst)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.1.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
