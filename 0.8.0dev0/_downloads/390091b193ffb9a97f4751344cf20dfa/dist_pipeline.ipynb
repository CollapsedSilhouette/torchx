{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install torchx[kfp]\n!wget --no-clobber https://github.com/pytorch/torchx/archive/refs/heads/main.tar.gz\n!tar xf main.tar.gz --strip-components=1\n\nNOTEBOOK = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDistributed KubeFlow Pipelines Example\n======================================\n\nThis is an example KFP pipeline that uses resource_from_app to launch a\ndistributed operator using the kubernetes/volcano job scheduler. This only works\nin Kubernetes KFP clusters with https://volcano.sh/en/docs/ installed on them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import kfp\nfrom torchx import specs\nfrom torchx.pipelines.kfp.adapter import resource_from_app\n\n\ndef pipeline() -> None:\n    # First we define our AppDef for the component, we set\n    echo_app = specs.AppDef(\n        name=\"test-dist\",\n        roles=[\n            specs.Role(\n                name=\"dist-echo\",\n                image=\"alpine\",\n                entrypoint=\"/bin/echo\",\n                args=[\"hello dist!\"],\n                num_replicas=3,\n            ),\n        ],\n    )\n\n    # To convert the TorchX AppDef into a KFP container we use\n    # the resource_from_app adapter. This takes generates a KFP Kubernetes\n    # resource operator definition from the TorchX app def and instantiates it.\n    echo_container: kfp.dsl.BaseOp = resource_from_app(echo_app, queue=\"default\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To generate the pipeline definition file we need to call into the KFP compiler\nwith our pipeline function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kfp.compiler.Compiler().compile(\n    pipeline_func=pipeline,\n    package_path=\"pipeline.yaml\",\n)\n\nwith open(\"pipeline.yaml\", \"rt\") as f:\n    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once this has all run you should have a pipeline file (typically\npipeline.yaml) that you can upload to your KFP cluster via the UI or\na kfp.Client.\n\nSee the\n`KFP SDK Examples <https://www.kubeflow.org/docs/components/pipelines/legacy-v1/tutorials/sdk-examples/#examples>`_\nfor more info on launching KFP pipelines.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See the `examples_pipelines/kfp/advanced_pipeline:Advanced KubeFlow Pipelines Example` for how to chain multiple\ncomponents together and use builtin components.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/img/gallery-kfp.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}